# Phase 5: Multi-Platform Replication Engine

**Phase ID:** PHASE-05  
**Status:** ğŸŸ¡ **PLANNED**  
**Priority:** HIGHEST (Premium Tier - $100/VM/month)  
**Timeline:** 12-16 weeks  
**Team Size:** 4-5 developers  
**Dependencies:** Phase 1-4 Complete

---

## ğŸ¯ Phase Objectives

**Primary Goal:** Enable "transcend" operations - near-live cross-platform replication

**Success Criteria:**
- âœ… **Hyper-V â†’ Any Platform** replication (RCT-based)
- âœ… **AWS EC2 â†’ Any Platform** replication (EBS CBT)
- âœ… **Azure VM â†’ Any Platform** replication (Managed Disk CBT)
- âœ… **Nutanix AHV â†’ Any Platform** replication (Native snapshots)
- âœ… **Bidirectional replication** (CloudStack â†” VMware, VMware â†” Hyper-V, etc.)
- âœ… **RTO: 5-15 minutes, RPO: 1-15 minutes** for all combinations
- âœ… **Test failover capability** without affecting production sync

**Strategic Value:**
- **Premium Tier:** $100/VM/month - THE MONEY MAKER ğŸ’°
- **Unique Market Position:** Only vendor with true any-to-any replication
- **Competitive Moat:** Extremely difficult to replicate (deep platform knowledge required)

---

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 5: MULTI-PLATFORM REPLICATION ARCHITECTURE (TRANSCEND)     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚    HYPER-V   â”‚     AWS      â”‚    AZURE     â”‚   NUTANIX    â”‚  â”‚
â”‚  â”‚   (Source)   â”‚   (Source)   â”‚   (Source)   â”‚  (Source)    â”‚  â”‚
â”‚  â”‚              â”‚              â”‚              â”‚              â”‚  â”‚
â”‚  â”‚ RCT Change   â”‚ EBS Changed  â”‚ Managed Disk â”‚ Native       â”‚  â”‚
â”‚  â”‚ Tracking     â”‚ Block Track  â”‚ CBT          â”‚ Snapshots    â”‚  â”‚
â”‚  â”‚      â†“       â”‚      â†“       â”‚      â†“       â”‚      â†“       â”‚  â”‚
â”‚  â”‚ Capture      â”‚ Capture      â”‚ Capture      â”‚ Capture      â”‚  â”‚
â”‚  â”‚ Agent        â”‚ Agent        â”‚ Agent        â”‚ Agent        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚              â”‚              â”‚              â”‚          â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                        â”‚              â”‚                         â”‚
â”‚                        â–¼              â–¼                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              REPLICATION HUB (Control Plane)               â”‚ â”‚
â”‚  â”‚                                                            â”‚ â”‚
â”‚  â”‚  â€¢ Multi-source stream aggregation                        â”‚ â”‚
â”‚  â”‚  â€¢ Change block deduplication                             â”‚ â”‚
â”‚  â”‚  â€¢ Bandwidth management                                   â”‚ â”‚
â”‚  â”‚  â€¢ Conflict resolution                                    â”‚ â”‚
â”‚  â”‚  â€¢ Test failover orchestration                           â”‚ â”‚
â”‚  â”‚                                                            â”‚ â”‚
â”‚  â”‚  REPLICATION MATRIX:                                      â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚ â”‚
â”‚  â”‚  â”‚ FROM/TO â”‚ VMware  â”‚CloudStckâ”‚ Hyper-V â”‚   AWS   â”‚...  â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”‚ â”‚
â”‚  â”‚  â”‚ VMware  â”‚   N/A   â”‚   âœ…   â”‚   NEW   â”‚   NEW   â”‚     â”‚ â”‚
â”‚  â”‚  â”‚CloudStckâ”‚   NEW   â”‚   N/A   â”‚   NEW   â”‚   NEW   â”‚     â”‚ â”‚
â”‚  â”‚  â”‚ Hyper-V â”‚   NEW   â”‚   NEW   â”‚   N/A   â”‚   NEW   â”‚     â”‚ â”‚
â”‚  â”‚  â”‚   AWS   â”‚   NEW   â”‚   NEW   â”‚   NEW   â”‚   N/A   â”‚     â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                        â†“ Target platform streaming              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   VMWARE     â”‚  CLOUDSTACK  â”‚   HYPER-V    â”‚    AWS EC2   â”‚  â”‚
â”‚  â”‚  (Target)    â”‚   (Target)   â”‚   (Target)   â”‚   (Target)   â”‚  â”‚
â”‚  â”‚              â”‚              â”‚              â”‚              â”‚  â”‚
â”‚  â”‚ vCenter API  â”‚ Volume       â”‚ PowerShell   â”‚ EBS Volume   â”‚  â”‚
â”‚  â”‚ VMDK Import  â”‚ Daemon âœ…    â”‚ VHDX Import  â”‚ Stream       â”‚  â”‚
â”‚  â”‚ VM Creation  â”‚ VM Creation  â”‚ VM Creation  â”‚ Instance     â”‚  â”‚
â”‚  â”‚              â”‚              â”‚              â”‚ Launch       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Replication Matrix (Complete)

### **Supported Replication Flows**

| Source Platform | Target Platform | Change Tracking | Status | Business Value |
|----------------|----------------|-----------------|--------|---------------|
| **VMware** â†’ CloudStack | CBT â†’ Volume Daemon | âœ… **EXISTING** | â­â­â­ UNIQUE |
| **CloudStack** â†’ VMware | Dirty Bitmap â†’ vCenter | ğŸ”¨ Phase 5A | â­â­â­ UNIQUE |
| **VMware** â†’ Hyper-V | CBT â†’ PowerShell | ğŸ”¨ Phase 5B | â­â­ HIGH |
| **Hyper-V** â†’ VMware | RCT â†’ vCenter | ğŸ”¨ Phase 5C | â­â­ HIGH |
| **VMware** â†’ AWS EC2 | CBT â†’ EBS Stream | ğŸ”¨ Phase 5D | â­â­ HIGH |
| **AWS EC2** â†’ VMware | EBS CBT â†’ vCenter | ğŸ”¨ Phase 5E | â­â­ HIGH |
| **Azure VM** â†’ VMware | Managed Disk â†’ vCenter | ğŸ”¨ Phase 5F | â­â­ HIGH |
| **Nutanix** â†’ VMware | Snapshots â†’ vCenter | ğŸ”¨ Phase 5G | â­ MEDIUM |
| **Hyper-V** â†’ CloudStack | RCT â†’ Volume Daemon | ğŸ”¨ Phase 5H | â­ MEDIUM |
| **CloudStack** â†’ AWS | Dirty Bitmap â†’ EBS | ğŸ”¨ Phase 5I | â­ MEDIUM |

**Total Combinations:** 30+ unique replication flows (any-to-any matrix)

---

## ğŸ“‹ Phase 5 Sub-Phases

### **Phase 5A: CloudStack â†’ VMware Replication** (Week 1-3)

**Goal:** Reverse replication (CloudStack source, VMware target)

**Why First:** 
- Reuses existing VMware target code (from Phase 4)
- Proves bidirectional capability
- High business value (unique market position)

**Architecture:**
```
CloudStack VM (Source)
  â†“ libvirt dirty bitmap
Capture Agent (KVM host)
  â†“ Changed blocks via NBD
Control Plane (Replication Hub)
  â†“ Incremental stream
VMware vCenter (Target)
  â†“ VMDK streaming import
Running VMware VM (Replica)
```

**Implementation:**
```go
func StartCloudStackToVMwareReplication(csVM CloudStackVM, vmwareTarget VMwareTarget) error {
    // 1. Setup dirty bitmap on CloudStack VM
    kvmAgent := getKVMAgent(csVM.HostID)
    err := kvmAgent.CreateDirtyBitmap(csVM.UUID)
    if err != nil {
        return err
    }
    
    // 2. Create target VMware VM (placeholder)
    vmwareClient := vmware.NewClient(vmwareTarget.Config)
    targetVM, err := vmwareClient.CreateReplicaVM(csVM.Specs)
    if err != nil {
        return err
    }
    
    // 3. Setup replication job
    replicationJob := ReplicationJob{
        SourcePlatform: "cloudstack",
        TargetPlatform: "vmware",
        SourceVMID: csVM.UUID,
        TargetVMID: targetVM.ID,
        SyncInterval: 10 * time.Minute,
    }
    
    // 4. Start initial full sync
    err = performFullReplication(replicationJob)
    if err != nil {
        return err
    }
    
    // 5. Schedule incremental syncs
    return scheduleIncrementalSync(replicationJob)
}
```

**Files to Create:**
```
source/current/control-plane/replication/
â”œâ”€â”€ cloudstack_source.go    # CloudStack replication source
â”œâ”€â”€ replication_hub.go      # Central replication coordination
â””â”€â”€ bidirectional_sync.go   # Handle reverse replication
```

**Success Criteria:**
- [ ] CloudStack VM replicates to VMware
- [ ] Incremental sync uses dirty bitmaps
- [ ] Performance: 3+ GiB/s
- [ ] Test failover works
- [ ] Failback capability (VMware â†’ CloudStack)

---

### **Phase 5B: Hyper-V Source Connector** (Week 3-5)

**Goal:** Add Hyper-V as replication source

**Architecture:**
```
Hyper-V Host
  â†“ RCT (Resilient Change Tracking)
Capture Agent (Windows Service)
  â†“ PowerShell/WMI API
  â†“ Read changed VHD blocks
  â†“ NBD stream over SSH
Control Plane
  â†“ Route to any target platform
VMware/CloudStack/AWS/Azure/Nutanix
```

**Key Technical Challenges:**

**1. RCT (Resilient Change Tracking)**
```powershell
# Enable RCT on Hyper-V VM
Enable-VMRCT -VMName "database-prod" -RCTFile "C:\RCT\database-prod.rct"

# Query changed blocks since last backup
Get-VMChangedBlocks -VMName "database-prod" -SinceRCT $lastRCTId

# Output: List of changed block ranges
# Block 1000-1999: Changed
# Block 5000-5999: Changed
```

**2. Windows Capture Agent**
```go
// Windows service for Hyper-V hosts
type HyperVCaptureAgent struct {
    psClient    *powershell.Client
    rctManager  *RCTManager
    nbdServer   *NBDServer
}

func (agent *HyperVCaptureAgent) StartReplication(vmName string) error {
    // 1. Enable RCT if not enabled
    err := agent.rctManager.EnableRCT(vmName)
    if err != nil {
        return err
    }
    
    // 2. Get changed blocks since last sync
    changedBlocks, err := agent.rctManager.GetChangedBlocks(vmName)
    if err != nil {
        return err
    }
    
    // 3. Export changed blocks via NBD
    export := agent.nbdServer.CreateExport(vmName + "-replication")
    
    // 4. Stream only changed blocks
    return agent.streamChangedBlocks(changedBlocks, export)
}
```

**Files to Create:**
```
source/current/capture-agent/hyperv/
â”œâ”€â”€ main.go                 # Windows service main
â”œâ”€â”€ rct_manager.go          # RCT operations
â”œâ”€â”€ powershell_client.go    # PowerShell integration
â”œâ”€â”€ vhd_reader.go           # VHD/VHDX file reading
â””â”€â”€ hyperv_api.go           # Hyper-V WMI/CIM API
```

**Deployment:**
```powershell
# Install as Windows service on Hyper-V hosts
sc create SendenseCaptureAgent binPath="C:\Sendense\capture-agent.exe"
sc start SendenseCaptureAgent
```

**Success Criteria:**
- [ ] RCT change tracking working
- [ ] Windows service stable
- [ ] Changed block detection accurate
- [ ] Replication to multiple targets
- [ ] Performance: 2+ GiB/s on Windows

---

### **Phase 5C: AWS EC2 Source Connector** (Week 5-7)

**Goal:** Add AWS EC2 as replication source

**Architecture:**
```
AWS EC2 Instance (Source)
  â†“ EBS Changed Block Tracking API
Capture Agent (EC2 instance or Lambda)
  â†“ EBS snapshot diffs
  â†“ Changed block streaming
Control Plane (Any location)
  â†“ Route to target platform
VMware/CloudStack/Hyper-V/Azure/Nutanix
```

**Key Technical Approach:**

**1. EBS Changed Block Tracking**
```go
// AWS EBS provides changed block tracking via API
func getChangedBlocks(volumeID, snapshotID1, snapshotID2 string) ([]ChangedBlock, error) {
    ebsClient := ec2.NewEBSClient()
    
    // Compare two snapshots to get changed blocks
    result, err := ebsClient.ListChangedBlocks(&ec2.ListChangedBlocksInput{
        FirstSnapshotId:  &snapshotID1,
        SecondSnapshotId: &snapshotID2,
    })
    
    var changedBlocks []ChangedBlock
    for _, block := range result.ChangedBlocks {
        changedBlocks = append(changedBlocks, ChangedBlock{
            Offset: *block.BlockIndex * 512 * 1024, // EBS uses 512KB blocks
            Length: 512 * 1024,
        })
    }
    
    return changedBlocks, err
}
```

**2. EBS Snapshot-Based Replication**
```go
type AWSCaptureAgent struct {
    ec2Client    *ec2.EC2
    ebsClient    *ec2.EBS
    instanceID   string
    volumeID     string
}

func (agent *AWSCaptureAgent) StartReplication(targetEndpoint string) error {
    // 1. Create baseline snapshot
    baseSnapshot, err := agent.ec2Client.CreateSnapshot(agent.volumeID)
    if err != nil {
        return err
    }
    
    // 2. Schedule incremental snapshots (every 10 minutes)
    go agent.incrementalSnapshotLoop(baseSnapshot.SnapshotID)
    
    // 3. Stream changed blocks to target
    return agent.streamChangesToTarget(targetEndpoint)
}

func (agent *AWSCaptureAgent) incrementalSnapshotLoop(baseSnapshotID string) {
    ticker := time.NewTicker(10 * time.Minute)
    for range ticker.C {
        // Create new snapshot
        newSnapshot, err := agent.ec2Client.CreateSnapshot(agent.volumeID)
        if err != nil {
            continue
        }
        
        // Get changed blocks
        changedBlocks, err := agent.getChangedBlocks(baseSnapshotID, newSnapshot.SnapshotID)
        if err != nil {
            continue
        }
        
        // Stream changes
        agent.streamChangedBlocks(changedBlocks)
        
        // Update baseline
        baseSnapshotID = newSnapshot.SnapshotID
    }
}
```

**Files to Create:**
```
source/current/capture-agent/aws/
â”œâ”€â”€ main.go                 # AWS agent main
â”œâ”€â”€ ebs_tracker.go          # EBS change tracking
â”œâ”€â”€ snapshot_manager.go     # Snapshot lifecycle
â”œâ”€â”€ ec2_metadata.go         # Instance metadata
â””â”€â”€ aws_api.go              # AWS SDK integration
```

**Deployment Options:**
- **Agent on EC2:** Run as service on source EC2 instance
- **Serverless:** Lambda function triggered by CloudWatch events
- **External:** Agent on separate EC2 instance with EBS access

**Success Criteria:**
- [ ] EBS changed block tracking working
- [ ] Snapshot-based incremental sync
- [ ] Multiple volume support (EC2 instances with multiple EBS)
- [ ] Cross-region replication
- [ ] Integration with AWS IAM/permissions

---

### **Phase 5D: Azure VM Source Connector** (Week 7-9)

**Goal:** Add Azure VMs as replication source

**Architecture:**
```
Azure VM (Source)
  â†“ Managed Disk Change Tracking
Capture Agent (Azure VM Extension or Service)
  â†“ Azure Backup API + Disk snapshots
  â†“ Changed block detection
Control Plane (Any location)
  â†“ Route to target platform
VMware/CloudStack/Hyper-V/AWS/Nutanix
```

**Key Technical Approach:**

**1. Azure Managed Disk Snapshots**
```go
// Azure provides incremental snapshots for Managed Disks
func createIncrementalSnapshot(diskID, sourceSnapshotID string) (*Snapshot, error) {
    snapshotClient := compute.NewSnapshotsClient(subscriptionID)
    
    snapshot := compute.Snapshot{
        Location: &location,
        SnapshotProperties: &compute.SnapshotProperties{
            CreationData: &compute.CreationData{
                CreateOption:     compute.DiskCreateOptionIncremental,
                SourceResourceID: &diskID,
                SourceUniqueID:   &sourceSnapshotID,
            },
        },
    }
    
    future, err := snapshotClient.CreateOrUpdate(ctx, resourceGroup, snapshotName, snapshot)
    return future.Result(snapshotClient)
}
```

**2. Azure Backup Integration**
```go
type AzureCaptureAgent struct {
    computeClient  *compute.VirtualMachinesClient
    diskClient     *compute.DisksClient
    snapshotClient *compute.SnapshotsClient
    vmID           string
}

func (agent *AzureCaptureAgent) StartReplication() error {
    // 1. Get VM's managed disks
    vm, err := agent.computeClient.Get(ctx, resourceGroup, vmName, "")
    disks := vm.StorageProfile.OsDisk // + DataDisks
    
    // 2. Create baseline snapshots
    for _, disk := range disks {
        snapshot, err := agent.createSnapshot(disk.ID)
        if err != nil {
            return err
        }
        agent.baselineSnapshots[disk.ID] = snapshot.ID
    }
    
    // 3. Schedule incremental snapshots
    go agent.incrementalReplicationLoop()
    
    return nil
}
```

**Files to Create:**
```
source/current/capture-agent/azure/
â”œâ”€â”€ main.go                 # Azure agent main
â”œâ”€â”€ managed_disk_tracker.go # Managed disk change tracking
â”œâ”€â”€ snapshot_manager.go     # Azure snapshot operations
â”œâ”€â”€ vm_extension.go         # Azure VM extension integration
â””â”€â”€ azure_api.go            # Azure SDK integration
```

**Deployment Options:**
- **VM Extension:** Deploy as Azure VM extension
- **Agent Service:** Run as service inside Azure VM
- **External Agent:** Separate Azure VM with disk access

**Success Criteria:**
- [ ] Managed disk snapshots working
- [ ] Incremental change detection
- [ ] Multi-disk Azure VMs supported
- [ ] Cross-region replication
- [ ] Azure AD authentication

---

### **Phase 5E: Nutanix AHV Source Connector** (Week 9-11)

**Goal:** Add Nutanix AHV as replication source

**Architecture:**
```
Nutanix AHV Cluster
  â†“ Nutanix native snapshots + CBT
Capture Agent (Nutanix CVM or external)
  â†“ Prism Central/Element API
  â†“ Changed block streaming
Control Plane
  â†“ Route to target platform
VMware/CloudStack/Hyper-V/AWS/Azure
```

**Key Technical Approach:**

**1. Nutanix Snapshot API**
```go
// Nutanix provides native snapshot and CBT capabilities
func createNutanixSnapshot(vmUUID string) (*Snapshot, error) {
    prismClient := nutanix.NewPrismClient(config)
    
    snapshotSpec := nutanix.SnapshotSpec{
        VMUUID:      vmUUID,
        Description: "Sendense replication point",
        SnapshotType: "APPLICATION_CONSISTENT", // Uses Nutanix Guest Tools
    }
    
    task, err := prismClient.CreateVMSnapshot(snapshotSpec)
    if err != nil {
        return nil, err
    }
    
    // Wait for completion
    return prismClient.WaitForTask(task.TaskUUID)
}
```

**2. Nutanix CBT Integration**
```go
type NutanixCaptureAgent struct {
    prismClient *nutanix.PrismClient
    vmUUID      string
    cbtEnabled  bool
}

func (agent *NutanixCaptureAgent) StartReplication() error {
    // 1. Enable CBT if available (Nutanix AOS 6.0+)
    if agent.checkCBTSupport() {
        err := agent.enableCBT(agent.vmUUID)
        if err != nil {
            log.Warn("CBT not available, falling back to snapshot diff")
        }
    }
    
    // 2. Create baseline snapshot
    baseSnapshot, err := agent.createSnapshot()
    if err != nil {
        return err
    }
    
    // 3. Setup incremental replication
    go agent.replicationLoop(baseSnapshot.UUID)
    
    return nil
}
```

**Files to Create:**
```
source/current/capture-agent/nutanix/
â”œâ”€â”€ main.go                 # Nutanix agent main
â”œâ”€â”€ prism_client.go         # Prism Central/Element API
â”œâ”€â”€ snapshot_manager.go     # Nutanix snapshot operations
â”œâ”€â”€ cbt_manager.go          # CBT integration (if available)
â””â”€â”€ ahv_integration.go      # AHV-specific operations
```

**Deployment Options:**
- **CVM Agent:** Run on Nutanix Controller VM
- **External Agent:** Separate VM with Prism API access
- **Container:** Run in Kubernetes on Nutanix (Karbon)

**Success Criteria:**
- [ ] Nutanix snapshot-based replication working
- [ ] CBT integration (where supported)
- [ ] Multi-disk VM support
- [ ] Cluster failover handling
- [ ] Prism Central/Element API compatibility

---

### **Phase 5F: Advanced Replication Features** (Week 11-14)

**Goal:** Enterprise replication features

**Sub-Tasks:**

**1. Test Failover (Without Production Impact)**
```go
func TestFailover(replicationJob ReplicationJob) error {
    // 1. Create snapshot of current replica
    replicaSnapshot := createTargetSnapshot(replicationJob.TargetVMID)
    
    // 2. Boot test VM from snapshot
    testVM, err := createTestVMFromSnapshot(replicaSnapshot)
    if err != nil {
        return err
    }
    
    // 3. Test VM functionality
    testResults := runTestSuite(testVM)
    
    // 4. Cleanup test VM (keep production replication running)
    destroyTestVM(testVM.ID)
    
    return reportTestResults(testResults)
}
```

**2. Failback Capability**
```go
func InitiateFailback(originalSource, currentTarget Platform) error {
    // 1. Set up reverse replication (target â†’ original source)
    reverseJob := ReplicationJob{
        SourcePlatform: currentTarget.Type,
        TargetPlatform: originalSource.Type,
        SourceVMID: currentTarget.VMID,
        TargetVMID: originalSource.VMID,
    }
    
    // 2. Sync changes from target back to original
    err := startReverseSync(reverseJob)
    if err != nil {
        return err
    }
    
    // 3. Coordinate cutover when ready
    return coordinateFailback(reverseJob)
}
```

**3. Bandwidth Management**
```go
type BandwidthManager struct {
    totalLimit    int64 // bytes per second
    activeJobs    map[string]*ReplicationJob
    rateLimiters  map[string]*rate.Limiter
}

func (bm *BandwidthManager) AllocateBandwidth(jobID string, priority Priority) *rate.Limiter {
    // Allocate bandwidth based on:
    // - Job priority (critical, normal, low)
    // - Time of day (business hours vs off-hours)
    // - Network utilization
    // - SLA requirements
    
    var allocation int64
    switch priority {
    case Critical:
        allocation = bm.totalLimit * 50 / 100  // 50% for critical
    case Normal:
        allocation = bm.totalLimit * 30 / 100  // 30% for normal
    case Low:
        allocation = bm.totalLimit * 20 / 100  // 20% for low
    }
    
    return rate.NewLimiter(rate.Limit(allocation), int(allocation))
}
```

**Files to Create:**
```
source/current/control-plane/replication/
â”œâ”€â”€ test_failover.go        # Test failover without impact
â”œâ”€â”€ failback_engine.go      # Reverse replication
â”œâ”€â”€ bandwidth_manager.go    # Bandwidth allocation
â”œâ”€â”€ replication_scheduler.go # Advanced scheduling
â””â”€â”€ conflict_resolver.go    # Handle replication conflicts
```

**Success Criteria:**
- [ ] Test failover works for all platforms
- [ ] Failback capability operational
- [ ] Bandwidth management effective
- [ ] No production impact during testing
- [ ] SLA compliance monitoring

---

### **Phase 5G: Replication Management & Monitoring** (Week 14-16)

**Goal:** Enterprise-grade replication management

**Features:**

**1. Replication Topology Visualization**
```
GUI Dashboard:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             Replication Topology Map                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  VMware DC (Primary)        CloudStack DC (DR)         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ ğŸ–¥ï¸ DB-Server01   â”‚â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ ğŸ–¥ï¸ DB-Server01-R â”‚        â”‚
â”‚  â”‚ ğŸ–¥ï¸ Web-Server02  â”‚â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ ğŸ–¥ï¸ Web-Server02-Râ”‚        â”‚
â”‚  â”‚ ğŸ–¥ï¸ App-Server03  â”‚â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ ğŸ–¥ï¸ App-Server03-Râ”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                         â”‚
â”‚  AWS EC2 (Cloud)                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
â”‚  â”‚ ğŸ–¥ï¸ Analytics-01  â”‚â—€â”€â”€â”€â”€â”€â”€ From CloudStack            â”‚
â”‚  â”‚ ğŸ–¥ï¸ ML-Server02   â”‚â—€â”€â”€â”€â”€â”€â”€ From VMware                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚
â”‚                                                         â”‚
â”‚  Status: ğŸŸ¢ All replications healthy                   â”‚
â”‚  Last Sync: 2 minutes ago | Next: 8 minutes           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**2. Replication Health Monitoring**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Replication Health (24 Active)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸŸ¢ Healthy: 22 replications                           â”‚
â”‚ ğŸŸ¡ Warning: 2 replications (lag >15 min)              â”‚
â”‚ ğŸ”´ Failed: 0 replications                             â”‚
â”‚                                                         â”‚
â”‚ âš ï¸  database-prod (VMwareâ†’CloudStack)                  â”‚
â”‚    Last sync: 18 minutes ago (target: 10 min)         â”‚
â”‚    Issue: Network latency spike                        â”‚
â”‚    Action: [Retry Now] [Adjust Schedule] [Details]     â”‚
â”‚                                                         â”‚
â”‚ âš ï¸  web-cluster-02 (Hyper-Vâ†’AWS)                       â”‚
â”‚    Last sync: 16 minutes ago (target: 10 min)         â”‚
â”‚    Issue: AWS API throttling                           â”‚
â”‚    Action: [Retry Now] [Adjust Schedule] [Details]     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**3. SLA Monitoring & Alerting**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SLA Compliance                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ RTO Target: 10 minutes    | Achieved: 8.2 min avg âœ…   â”‚
â”‚ RPO Target: 5 minutes     | Achieved: 4.1 min avg âœ…   â”‚
â”‚                                                         â”‚
â”‚ This Month (October 2025):                             â”‚
â”‚ â€¢ SLA Breaches: 2 (0.3% of replications)              â”‚
â”‚ â€¢ Availability: 99.97% (target: 99.9%)                â”‚
â”‚ â€¢ Mean Sync Time: 4.1 minutes                         â”‚
â”‚ â€¢ p95 Sync Time: 8.3 minutes                          â”‚
â”‚                                                         â”‚
â”‚ Trending: â†— Availability up 0.02%                     â”‚
â”‚           â†’ RTO/RPO stable                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Files to Create:**
```
source/current/control-plane/monitoring/
â”œâ”€â”€ replication_monitor.go  # Health monitoring
â”œâ”€â”€ sla_tracker.go          # SLA compliance tracking
â”œâ”€â”€ alert_manager.go        # Alerting rules
â””â”€â”€ topology_mapper.go      # Replication topology
```

**Success Criteria:**
- [ ] Real-time replication health monitoring
- [ ] SLA tracking and reporting
- [ ] Proactive alerting on issues
- [ ] Topology visualization
- [ ] Performance trending analysis

---

## ğŸ’° Business Impact & Pricing

### **Replication Edition Revenue Model**

**Pricing Structure:**
- **Base Price:** $100/VM/month for replication
- **Additional Platforms:** +$25/VM/month per additional target
- **Premium Support:** +$50/VM/month (24/7, 1-hour response)

**Example Customer: 500-VM Enterprise**
- **Core Replication:** 50 critical VMs Ã— $100 = $5,000/month
- **Multi-Target:** 20 VMs Ã— $25 (replicate to 2nd platform) = $500/month
- **Standard Backup:** 450 VMs Ã— $10 = $4,500/month
- **Total:** $10,000/month ($120K annual)

### **Market Positioning**

**vs PlateSpin Migrate:**
- **PlateSpin:** $150/VM, limited platforms, legacy UI
- **Sendense:** $100/VM, any-to-any platforms, modern UI
- **Advantage:** 33% cost savings + more platforms

**vs Carbonite Migrate:**
- **Carbonite:** $80-120/VM, fewer platforms
- **Sendense:** $100/VM, more platforms, better performance
- **Advantage:** Platform breadth + performance

**Unique Selling Points:**
1. **VMware â†’ CloudStack** (only vendor)
2. **Any-to-any replication matrix** (30+ combinations)
3. **Test failover without impact** (most vendors can't do this)
4. **Modern architecture** (not legacy Windows-based)

---

## ğŸ¯ Success Metrics

### **Technical Success**
- âœ… All 6 source platforms replicate successfully
- âœ… All 6 target platforms receive replication
- âœ… RTO <15 minutes for 95% of failovers
- âœ… RPO <10 minutes for 95% of replications
- âœ… 99.9% replication uptime

### **Performance Success**
- âœ… Throughput: 2+ GiB/s for all platform combinations
- âœ… Incremental efficiency: 95%+ data reduction
- âœ… Concurrent replications: 50+ per Control Plane
- âœ… Multi-platform support without performance degradation

### **Business Success**
- âœ… Premium tier customers (Replication Edition)
- âœ… Average selling price >$50/VM (mix of tiers)
- âœ… Customer retention >95% (sticky premium features)
- âœ… Competitive wins against PlateSpin/Carbonite

---

## ğŸ›¡ï¸ Risk Management

### **Technical Risks**

**Risk 1: Platform API Changes**
- **Probability:** Medium
- **Impact:** High
- **Mitigation:** API versioning, compatibility testing, vendor relationships

**Risk 2: Performance Degradation**
- **Probability:** Medium  
- **Impact:** Medium
- **Mitigation:** Performance SLAs, automated testing, optimization

**Risk 3: Replication Conflicts**
- **Probability:** Low
- **Impact:** High
- **Mitigation:** Conflict detection, automated resolution, manual override

### **Business Risks**

**Risk 1: Market Competition**
- **Probability:** High (Veeam will respond)
- **Impact:** Medium
- **Mitigation:** First-mover advantage, patent filing, feature velocity

**Risk 2: Customer Support Complexity**
- **Probability:** Medium
- **Impact:** Medium
- **Mitigation:** Extensive documentation, training, tiered support

---

## ğŸ“š Documentation Deliverables

1. **Replication Architecture Guide**
   - Platform-specific implementation details
   - Performance tuning guide
   - Troubleshooting runbook

2. **API Documentation**
   - Replication management APIs
   - Platform connector interfaces
   - Monitoring and alerting APIs

3. **User Guides**
   - Setting up cross-platform replication
   - Test failover procedures
   - Failback workflows

4. **Admin Guides**
   - Multi-platform agent deployment
   - Performance monitoring and optimization
   - SLA management

---

## ğŸ”— Dependencies & Next Steps

**Dependencies:**
- Phase 1-4 completed (backup/restore foundation)
- Platform access credentials (vCenter, CloudStack, AWS, Azure, Nutanix)
- Test environments for all platforms
- Performance testing infrastructure

**Enables:**
- **Premium Pricing:** $100/VM/month tier
- **Market Differentiation:** Any-to-any replication matrix
- **Competitive Advantage:** Unique VMware â†” CloudStack capability

**Next Phase:**
â†’ **Phase 6: Application-Aware Restores** (SQL, AD, Exchange granular recovery)

---

## ğŸ¯ Success Definition

**Phase 5 is successful when:**
- Customer can replicate ANY VM from ANY platform TO any other platform
- Test failover works without impacting production replication
- Failback capability enables temporary platform switching
- SLA compliance monitoring ensures business requirements met
- Revenue targets achieved with premium tier adoption

**This is the phase that establishes Sendense as the premier cross-platform replication solution.**

---

**Phase Owner:** Replication Engineering Team  
**Last Updated:** October 4, 2025  
**Status:** ğŸŸ¡ Planned - Highest Revenue Impact ($100/VM Premium Tier)
